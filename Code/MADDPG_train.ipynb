{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "MADDPG_full_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wAZcnqj5isn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def hidden_values(layer):\n",
        "    wts = layer.weight.data.size()[0]\n",
        "    lim = 1. / np.sqrt(wts)\n",
        "    return (-lim, lim)\n",
        "\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed=0, fc1_dims=256, fc2_dims=128):\n",
        "\n",
        "        super(Actor, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, fc1_dims)\n",
        "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "        self.fc3 = nn.Linear(fc2_dims, action_size)\n",
        "        self.bn1 = nn.BatchNorm1d(fc1_dims)\n",
        "        self.bn2 = nn.BatchNorm1d(fc2_dims)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.fc1.weight.data.uniform_(*hidden_values(self.fc1))\n",
        "        self.fc2.weight.data.uniform_(*hidden_values(self.fc2))\n",
        "        self.fc3.weight.data.uniform_(-0.003, 0.003)\n",
        "\n",
        "    def forward(self, state):\n",
        "\n",
        "        if state.dim() == 1:\n",
        "            state = torch.unsqueeze(state,0)\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return torch.tanh(self.fc3(x))\n",
        "\n",
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, full_state_size, actions_size, seed=0, fcs1_units=256, fc2_dims=128):\n",
        "       \n",
        "        super(Critic, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fcs1 = nn.Linear(full_state_size, fcs1_units)\n",
        "        self.fc2 = nn.Linear(fcs1_units+actions_size, fc2_dims)\n",
        "        self.fc3 = nn.Linear(fc2_dims, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(fcs1_units)\n",
        "        self.bn2 = nn.BatchNorm1d(fc2_dims)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.fcs1.weight.data.uniform_(*hidden_values(self.fcs1))\n",
        "        self.fc2.weight.data.uniform_(*hidden_values(self.fc2))\n",
        "        self.fc3.weight.data.uniform_(-0.003, 0.003)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        xs = F.relu(self.fcs1(state))\n",
        "        xs = self.bn1(xs)\n",
        "        x = torch.cat((xs, action), dim=1)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwvTWaG5bqU"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "#from nn_model import Actor, Critic\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "replaymem_size = 1000   # replay buffer size\n",
        "batch_size = 128        # batch size\n",
        "tau = 0.001              # for soft update of target parameters\n",
        "alpha = 0.001         # learning rate of the actor\n",
        "beta = 0.003        # learning rate of the critic\n",
        "weight_decay = 0        # 2nd layer weight decay\n",
        "\n",
        "noise_reductionrate = 0.99\n",
        "eps_beforetraining = 100\n",
        "initial_noise = 1.0\n",
        "final_noise = 0.1\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Agent():\n",
        "\n",
        "    def __init__(self, state_size, action_size, num_agents, seed_value):\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed_value)\n",
        "\n",
        "        self.actor_current = Actor(state_size, action_size, seed_value).to(device)\n",
        "        self.actor_target = Actor(state_size, action_size, seed_value).to(device)\n",
        "        self.actor_optimizer = optim.Adam(self.actor_current.parameters(), lr=alpha)\n",
        "\n",
        "        self.critic_current = Critic(state_size*num_agents, action_size*num_agents, seed_value).to(device)\n",
        "        self.critic_target = Critic(state_size*num_agents, action_size*num_agents, seed_value).to(device)\n",
        "        self.critic_optimizer = optim.Adam(self.critic_current.parameters(), lr=beta, weight_decay=weight_decay)\n",
        "\n",
        "        self.soft_update(self.critic_current, self.critic_target, 1)\n",
        "        self.soft_update(self.actor_current, self.actor_target, 1)\n",
        "\n",
        "        self.noise = OUNoise(action_size, seed_value)\n",
        "        self.noise_reduction_ratio = initial_noise\n",
        "\n",
        "    def act(self, state, eps_num, add_noise=True):\n",
        "\n",
        "        state = torch.from_numpy(state).float().to(device)\n",
        "        self.actor_current.eval()\n",
        "        with torch.no_grad():\n",
        "            action = self.actor_current(state).cpu().data.numpy()\n",
        "        self.actor_current.train()\n",
        "\n",
        "        if add_noise:\n",
        "            if eps_num > eps_beforetraining and self.noise_reduction_ratio > final_noise :\n",
        "                self.noise_reduction_ratio = noise_reductionrate**(eps_num-eps_beforetraining)\n",
        "            action += self.noise_reduction_ratio * self.add_noise2()\n",
        "        return np.clip(action, -1, 1)\n",
        "\n",
        "    def add_noise2(self):\n",
        "        noise = 0.5*np.random.standard_normal(self.action_size)\n",
        "        return noise\n",
        "\n",
        "    def reset(self):\n",
        "        self.noise.reset()\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "\n",
        "        full_states, actions, actor_current_actions, actor_target_actions, agent_state, agent_action, agent_reward, agent_done, next_states, next_full_states = experiences\n",
        "\n",
        "        #update critic\n",
        "        Q_targets_next = self.critic_target(next_full_states, actor_target_actions)\n",
        "        Q_targets = agent_reward + (gamma * Q_targets_next * (1 - agent_done))\n",
        "        Q_expected = self.critic_current(full_states, actions)\n",
        "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        #update actor\n",
        "        actor_loss = -self.critic_current(full_states, actor_current_actions).mean()\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "    def hard_copy_weights(self, target, source):\n",
        "\n",
        "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "\n",
        "    def soft_update(self, current_model, target_model, tau):\n",
        "\n",
        "        for target_param, local_param in zip(target_model.parameters(), current_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
        "\n",
        "class OUNoise:\n",
        "\n",
        "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.1):\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.seed = random.seed(seed)\n",
        "        self.reset()\n",
        "        self.size = size\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(self.size)\n",
        "        self.state = x +dx\n",
        "        return self.state\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWGVmyJP5OA9"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "import numpy as np\n",
        "\n",
        "#from ddpg import Agent\n",
        "\n",
        "replaymem_size = 10000  # replay buffer size\n",
        "batch_size = 128        # batch size\n",
        "gamma = 0.99            # discount factor\n",
        "tau = 0.001             # for soft update of target parameters\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MADDPG():\n",
        "    \n",
        "    def __init__(self, state_size, action_size, num_agents, seed_value):\n",
        "        \n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed_value = random.seed(seed_value)\n",
        "\n",
        "        self.agents = [Agent(state_size, action_size, num_agents, seed_value) for i in range(num_agents)]\n",
        "        self.batch_memory = replay_buffer(replaymem_size, batch_size, seed_value)\n",
        " \n",
        "    def reset_noise(self):\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "\n",
        "    def act(self, state, eps_num , add_noise=True):\n",
        "        actions = []\n",
        "        for agent_state, agent in zip(state, self.agents):\n",
        "            action = agent.act(agent_state, eps_num , add_noise)\n",
        "            action = np.reshape(action, newshape=(-1))\n",
        "            actions.append(action)\n",
        "        actions = np.stack(actions)\n",
        "        return actions\n",
        "\n",
        "    def step(self, eps_num , state, action, reward, next_state, done):\n",
        "        full_state = np.reshape(state, newshape=(-1)) #Joining all states into 1D array\n",
        "        next_full_state = np.reshape(next_state, newshape=(-1)) #Joining all states into 1D array\n",
        "        \n",
        "        self.batch_memory.add(state, full_state, action, reward, next_state, next_full_state, done)\n",
        "        \n",
        "        if len(self.batch_memory) > batch_size and eps_num  > 100:\n",
        "            for l_cnt in range(3):\n",
        "                for agent in self.agents:\n",
        "                    experiences = self.batch_memory.sample_experiences()\n",
        "                    self.learn(experiences, agent, gamma)\n",
        "\n",
        "                for agent in self.agents:\n",
        "                    agent.soft_update(agent.actor_current, agent.actor_target, tau)\n",
        "                    agent.soft_update(agent.critic_current, agent.critic_target, tau)\n",
        "  \n",
        "    def learn(self, experiences, agent, gamma):\n",
        "        states, full_states, actions, rewards, next_states, next_full_states, dones = experiences\n",
        "        actor_target_actions = torch.zeros(actions.shape, dtype=torch.float, device=device)\n",
        "        for agent_num, agent_i in enumerate(self.agents):\n",
        "            if agent == agent_i:\n",
        "                agent_id = agent_num\n",
        "            agent_i_current_state = states[:,agent_num]\n",
        "            actor_target_actions[:,agent_num] = agent_i.actor_target.forward(agent_i_current_state)\n",
        "        actor_target_actions = actor_target_actions.view(batch_size, -1)\n",
        "        agent_state = states[:,agent_id]\n",
        "        agent_action = actions[:,agent_id]\n",
        "        agent_reward = rewards[:,agent_id].view(-1,1)\n",
        "        agent_done = dones[:,agent_id].view(-1,1)\n",
        "        \n",
        "        actor_local_actions = actions.clone()\n",
        "        actor_local_actions[:, agent_id] = agent.actor_current.forward(agent_state)\n",
        "        actor_local_actions = actor_local_actions.view(batch_size, -1)\n",
        "        actions = actions.view(batch_size, -1)\n",
        "        \n",
        "        agent_experience = (full_states, actions, actor_local_actions, actor_target_actions,\n",
        "                            agent_state, agent_action, agent_reward, agent_done,\n",
        "                            next_states, next_full_states)\n",
        "\n",
        "        agent.learn(agent_experience, gamma)\n",
        "\n",
        "    def save(self):\n",
        "        for idx, agent in enumerate(self.agents):\n",
        "            chk_actor_filename = '/content/sample_data/checkpoint_agent{}_actor.pth'.format(idx)\n",
        "            chk_critic_filename = '/content/sample_data/checkpoint_critic{}_critic.pth'.format(idx)\n",
        "            torch.save(agent.actor_current.state_dict(), chk_actor_filename)\n",
        "            torch.save(agent.critic_current.state_dict(), chk_critic_filename)\n",
        "\n",
        "class replay_buffer(object):\n",
        "\n",
        "    def __init__(self, replaymem_size, batch_size, seed):\n",
        "\n",
        "        self.batch_memory = deque(maxlen=replaymem_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=['state', 'full_state', 'action', 'reward', 'next_state', 'next_full_state','done'])\n",
        "        self.seed = random.seed(seed)\n",
        "    \n",
        "    def add(self, state, full_state, action, reward, next_state, next_full_state, done):\n",
        "        e = self.experience(state, full_state, action, reward, next_state, next_full_state, done)\n",
        "        self.batch_memory.append(e)\n",
        "    \n",
        "    def sample_experiences(self):\n",
        "        experiences = random.sample(self.batch_memory, k=self.batch_size)\n",
        "        \n",
        "        states = torch.from_numpy(np.array([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        full_states = torch.from_numpy(np.array([e.full_state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.array([e.action for e in experiences if e is not None])).float().to(device)\n",
        "        rewards = torch.from_numpy(np.array([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.array([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        next_full_states = torch.from_numpy(np.array([e.next_full_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.array([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, full_states, actions, rewards, next_states, next_full_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_memory)    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCbuQ846TKE"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "action_new = 0\n",
        "\n",
        "def priority_action(state):\n",
        "    if state[2] == 3:\n",
        "        return 2\n",
        "    else:\n",
        "        return np.argmax(state)\n",
        "\n",
        "def goal_state(cur_state):\n",
        "    if(np.sum(cur_state)==3):\n",
        "        done = True\n",
        "        return done\n",
        "\n",
        "def checkBoundaries(good, cur_state):\n",
        "    cur_state = np.int_(cur_state)\n",
        "    for i in range(np.size(cur_state)):\n",
        "        if (cur_state[i]>3 or cur_state[i]<1):\n",
        "            done = True\n",
        "            reward = -2\n",
        "            return reward, done\n",
        "\n",
        "    done = False\n",
        "    if good == 1:\n",
        "        reward = 1\n",
        "    else:\n",
        "        reward = -1\n",
        "\n",
        "    return reward, done\n",
        "\n",
        "def actionClassifier(action_val):\n",
        "    global action_new\n",
        "    if action_val >=-1.0 and action_val < -0.334:\n",
        "        action_new = 0\n",
        "    elif action_val >=-0.334 and action_val < 0.332:\n",
        "        action_new = 1\n",
        "    elif action_val >=0.332 and action_val <= 1.0:\n",
        "        action_new = 2\n",
        "\n",
        "    return action_new\n",
        "\n",
        "\n",
        "def nextState(good, cur_state):\n",
        "\n",
        "    if good == 1:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]-1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "\n",
        "    elif good == 0:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]+1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "\n",
        "class Hospital_Agent():\n",
        "  \n",
        "    def step(self, action, cur_state):\n",
        "\n",
        "        action = actionClassifier(action)\n",
        "\n",
        "        done = False\n",
        "        cur_state = np.array(cur_state)\n",
        "        done = goal_state(cur_state)\n",
        "        if done == True:\n",
        "            reward = 10\n",
        "            return cur_state, reward, done, {}\n",
        "\n",
        "        else:\n",
        "            self.priority = priority_action(cur_state)\n",
        "\n",
        "            if(action == self.priority):\n",
        "                self.good = 1\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "            elif(action != self.priority):\n",
        "                self.good = 0\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "        return (nextstate), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.elec_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trans_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trend_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.state = np.array([self.elec_random, self.trans_random, self.trend_random])\n",
        "        return self.state\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp8ye97-63xa"
      },
      "source": [
        " \n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "action_new = 0\n",
        "\n",
        "def priority_action(state):\n",
        "    if state[0] == 3:\n",
        "        return 0\n",
        "    else:\n",
        "        return np.argmax(state)\n",
        "\n",
        "def goal_state(cur_state):\n",
        "    if(np.sum(cur_state)==3):\n",
        "        done = True\n",
        "        return done\n",
        "\n",
        "def checkBoundaries(good, cur_state):\n",
        "    cur_state = np.int_(cur_state)\n",
        "    for i in range(np.size(cur_state)):\n",
        "        if (cur_state[i]>3 or cur_state[i]<1):\n",
        "            done = True\n",
        "            reward = -2\n",
        "            return reward, done\n",
        "\n",
        "    done = False\n",
        "    if good == 1:\n",
        "        reward = 1\n",
        "    else:\n",
        "        reward = -1\n",
        "\n",
        "    return reward, done\n",
        "\n",
        "def actionClassifier(action_val):\n",
        "    global action_new\n",
        "    if action_val >=-1.0 and action_val < -0.334:\n",
        "        action_new = 0\n",
        "    elif action_val >=-0.334 and action_val < 0.332:\n",
        "        action_new = 1\n",
        "    elif action_val >=0.332 and action_val <= 1.0:\n",
        "        action_new = 2\n",
        "\n",
        "    return action_new\n",
        "\n",
        "\n",
        "def nextState(good, cur_state):  \n",
        "\n",
        "    if good == 1:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]-1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "\n",
        "    elif good == 0:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]+1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "      \n",
        "class Powerstation_Agent():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.action_space = spaces.Box(\n",
        "            low= -1.0,\n",
        "            high=1.0,\n",
        "            shape=(1,),\n",
        "            dtype=np.float32 )\n",
        "        \n",
        "    def step(self, action, cur_state):\n",
        "\n",
        "        action = actionClassifier(action)\n",
        "    \n",
        "        done = False\n",
        "        cur_state = np.array(cur_state)\n",
        "        done = goal_state(cur_state)\n",
        "        if done == True:\n",
        "            reward = 10\n",
        "            return cur_state, reward, done, {}\n",
        "\n",
        "        else:\n",
        "            self.priority = priority_action(cur_state)\n",
        "\n",
        "            if(action == self.priority):\n",
        "                self.good = 1\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "            elif(action != self.priority):\n",
        "                self.good = 0\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "        return (nextstate), reward, done, {}\n",
        "    \n",
        "    def reset(self):\n",
        "        self.elec_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trans_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trend_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.state = np.array([self.elec_random, self.trans_random, self.trend_random])\n",
        "        return self.state\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBMP_lhr7CRO"
      },
      "source": [
        " \n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "action_new = 0\n",
        "\n",
        "def priority_action(state):\n",
        "    if state[1] == 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return np.argmax(state)\n",
        "    # temp = []\n",
        "    # max = np.argmax(state)\n",
        "    # for i in range(np.size(state)):\n",
        "    #     if(state[i]==state[max]):\n",
        "    #         temp.append(i)\n",
        "    # return np.random.choice(temp)\n",
        "\n",
        "def goal_state(cur_state):\n",
        "    if(np.sum(cur_state)==3):\n",
        "        done = True\n",
        "        return done\n",
        "\n",
        "def checkBoundaries(good, cur_state):\n",
        "    cur_state = np.int_(cur_state)\n",
        "    for i in range(np.size(cur_state)):\n",
        "        if (cur_state[i]>3 or cur_state[i]<1):\n",
        "            done = True\n",
        "            reward = -2\n",
        "            return reward, done\n",
        "\n",
        "    done = False\n",
        "    if good == 1:\n",
        "        reward = 1\n",
        "    else:\n",
        "        reward = -1\n",
        "\n",
        "    return reward, done\n",
        "\n",
        "def actionClassifier(action_val):\n",
        "    global action_new\n",
        "    if action_val >=-1.0 and action_val < -0.334:\n",
        "        action_new = 0\n",
        "    elif action_val >=-0.334 and action_val < 0.332:\n",
        "        action_new = 1\n",
        "    elif action_val >=0.332 and action_val <= 1.0:\n",
        "        action_new = 2\n",
        "\n",
        "    return action_new\n",
        "\n",
        "\n",
        "def nextState(good, cur_state):  \n",
        "\n",
        "    if good == 1:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]-1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "\n",
        "    elif good == 0:\n",
        "        index = np.argmax(cur_state)\n",
        "        cur_state[index] = cur_state[index]+1\n",
        "        reward, done = checkBoundaries(good, cur_state)\n",
        "        next_state = np.copy(cur_state)\n",
        "        return next_state, reward, done\n",
        "      \n",
        "class Transport_Agent():\n",
        "\n",
        "    def __init__(self):\n",
        "    \n",
        "        self.action_space = spaces.Box(\n",
        "            low= -1.0,\n",
        "            high=1.0,\n",
        "            shape=(1,),\n",
        "            dtype=np.float32 )\n",
        "        \n",
        "    def step(self, action, cur_state):\n",
        "\n",
        "        action = actionClassifier(action)\n",
        "    \n",
        "        done = False\n",
        "        cur_state = np.array(cur_state)\n",
        "        done = goal_state(cur_state)\n",
        "        if done == True:\n",
        "            reward = 10\n",
        "            return cur_state, reward, done, {}\n",
        "\n",
        "        else:\n",
        "            self.priority = priority_action(cur_state)\n",
        "\n",
        "            if(action == self.priority):\n",
        "                self.good = 1\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "            elif(action != self.priority):\n",
        "                self.good = 0\n",
        "                nextstate, reward, done = nextState(self.good, cur_state)\n",
        "\n",
        "        return (nextstate), reward, done, {}\n",
        "    \n",
        "    def reset(self):\n",
        "        self.elec_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trans_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.trend_random = np.random.choice(np.array([1,2,3]))\n",
        "        self.state = np.array([self.elec_random, self.trans_random, self.trend_random])\n",
        "        return self.state\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kegv2k946RK_"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "hospital = Hospital_Agent()\n",
        "power = Powerstation_Agent()\n",
        "trans = Transport_Agent()\n",
        "\n",
        "h_returns = []\n",
        "next_states = []\n",
        "rewards = []\n",
        "dones = []\n",
        "info = []\n",
        "\n",
        "class env():\n",
        "\n",
        "    def __init__(self, num_agents=3, state_space=3, action_space=1):\n",
        "\n",
        "        self.num_agents = num_agents\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "       \n",
        "    def reset_all():\n",
        "    \n",
        "        h_env = np.array(hospital.reset())\n",
        "        p_env = np.array(power.reset())\n",
        "        w_env = np.array(trans.reset())\n",
        "        \n",
        "        return np.array([p_env, w_env, h_env])\n",
        "    \n",
        "    def step(action, cur_state):\n",
        "\n",
        "        h_returns = []\n",
        "     \n",
        "        h_returns.append(power.step(action[0], cur_state[0]))\n",
        "        h_returns.append(trans.step(action[1], cur_state[1]))\n",
        "        h_returns.append(hospital.step(action[2], cur_state[2]))\n",
        "        \n",
        "        h_returns_f = np.array(h_returns)\n",
        "\n",
        "        next_states = []\n",
        "        rewards = []\n",
        "        dones = []\n",
        "        info = []\n",
        "\n",
        "        for i in range(3):\n",
        "\n",
        "            next_states.append(h_returns_f[i, 0])\n",
        "            rewards.append(h_returns_f[i, 1])\n",
        "            dones.append(h_returns_f[i, 2])\n",
        "            info.append(h_returns_f[i, 3])\n",
        "\n",
        "        return (next_states), (rewards), (dones), (info)\n",
        "        # [0]=next state, [1] = reward, [2] = done, [3] = {}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5idaO137UOp"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "def plotLearning(scores, filename, x=None, window=5):   \n",
        "    N = len(scores)\n",
        "    running_avg = np.empty(N)\n",
        "    for t in range(N):\n",
        "\t    running_avg[t] = np.mean(scores[max(0, t-window):(t+1)])\n",
        "    if x is None:\n",
        "        x = [i for i in range(N)]\n",
        "    plt.ylabel('Reward')       \n",
        "    plt.xlabel('Episode')                     \n",
        "    plt.plot(x, running_avg)\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YowXrDOLWZ7y"
      },
      "source": [
        "import torch\n",
        "#from maddpg import MADDPG\n",
        "from collections import deque\n",
        "#from Agents.full_env import env\n",
        "import time, os\n",
        "import numpy as np\n",
        "#from graph import plotLearning"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIwFvyH9U2Hl"
      },
      "source": [
        "#statesize, actionsize, no of agents, random seed\n",
        "num_agents = 3\n",
        "action_size = 1\n",
        "state_size = 3\n",
        "seed = 20\n",
        "maddpg = MADDPG(num_agents, action_size, state_size, seed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4eZ3EGOU2Ho"
      },
      "source": [
        "scores_max_hist = []\n",
        "scores_mean_hist = []\n",
        "n_episodes = 750"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Aq_OheU2Hr"
      },
      "source": [
        "def maddpg_train(n_episodes):\n",
        "    \n",
        "    scores_deque = deque(maxlen=100)\n",
        "    solved = False\n",
        "    \n",
        "    for i_episode in range(n_episodes):\n",
        "        cur_states = env.reset_all()\n",
        "        #print(cur_states)\n",
        "        scores = np.zeros(num_agents)\n",
        "        maddpg.reset_noise()\n",
        "        step = 0\n",
        "        while True:\n",
        "            \n",
        "            step+=1\n",
        "            actions = maddpg.act(cur_states, i_episode)\n",
        "            #print(actions)\n",
        "            next_states,  rewards, dones, info = env.step(actions,cur_states)\n",
        "            #print(next_states,  rewards, dones, info)\n",
        "\n",
        "            scores += rewards\n",
        "            \n",
        "            maddpg.step(i_episode, cur_states, actions, rewards, next_states, dones)\n",
        "            \n",
        "            if np.any(dones):\n",
        "                break\n",
        "                \n",
        "            cur_states = next_states\n",
        "            \n",
        "        score_max = np.max(scores)\n",
        "        scores_deque.append(score_max)\n",
        "        score_mean = np.mean(scores_deque)\n",
        "        \n",
        "        scores_max_hist.append(score_max)\n",
        "        scores_mean_hist.append(score_mean)\n",
        "        \n",
        "        print('\\n{} episode\\tavg score {:.5f}\\tmax score {:.5f}'.format(i_episode, np.mean(scores_deque), score_max), end='')\n",
        "        if solved == False and score_mean >= 11:\n",
        "            print('\\nEnvironment solved after {} episodes with the average score {}\\n'.format(i_episode, score_mean))\n",
        "            maddpg.save()\n",
        "            solved = True\n",
        "            break\n",
        "\n",
        "    filename = 'maddpg.png'\n",
        "    plotLearning(scores_mean_hist, filename, window=100)\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7mHTrbG_Xirp",
        "outputId": "683ee790-0728-4c53-fc73-c0383fb17b33"
      },
      "source": [
        "maddpg_train(n_episodes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0 episode\tavg score 2.00000\tmax score 2.00000\n",
            "1 episode\tavg score 1.50000\tmax score 1.00000\n",
            "2 episode\tavg score 1.33333\tmax score 1.00000\n",
            "3 episode\tavg score 1.25000\tmax score 1.00000\n",
            "4 episode\tavg score 1.40000\tmax score 2.00000\n",
            "5 episode\tavg score 1.33333\tmax score 1.00000\n",
            "6 episode\tavg score 1.28571\tmax score 1.00000\n",
            "7 episode\tavg score 1.25000\tmax score 1.00000\n",
            "8 episode\tavg score 2.33333\tmax score 11.00000\n",
            "9 episode\tavg score 2.20000\tmax score 1.00000\n",
            "10 episode\tavg score 2.09091\tmax score 1.00000\n",
            "11 episode\tavg score 2.00000\tmax score 1.00000\n",
            "12 episode\tavg score 2.61538\tmax score 10.00000\n",
            "13 episode\tavg score 2.28571\tmax score -2.00000\n",
            "14 episode\tavg score 2.06667\tmax score -1.00000\n",
            "15 episode\tavg score 2.00000\tmax score 1.00000\n",
            "16 episode\tavg score 1.94118\tmax score 1.00000\n",
            "17 episode\tavg score 1.88889\tmax score 1.00000\n",
            "18 episode\tavg score 1.68421\tmax score -2.00000\n",
            "19 episode\tavg score 1.50000\tmax score -2.00000\n",
            "20 episode\tavg score 1.38095\tmax score -1.00000\n",
            "21 episode\tavg score 1.36364\tmax score 1.00000\n",
            "22 episode\tavg score 1.73913\tmax score 10.00000\n",
            "23 episode\tavg score 1.70833\tmax score 1.00000\n",
            "24 episode\tavg score 1.60000\tmax score -1.00000\n",
            "25 episode\tavg score 1.57692\tmax score 1.00000\n",
            "26 episode\tavg score 1.55556\tmax score 1.00000\n",
            "27 episode\tavg score 1.46429\tmax score -1.00000\n",
            "28 episode\tavg score 1.75862\tmax score 10.00000\n",
            "29 episode\tavg score 1.73333\tmax score 1.00000\n",
            "30 episode\tavg score 1.64516\tmax score -1.00000\n",
            "31 episode\tavg score 1.62500\tmax score 1.00000\n",
            "32 episode\tavg score 1.60606\tmax score 1.00000\n",
            "33 episode\tavg score 1.58824\tmax score 1.00000\n",
            "34 episode\tavg score 1.82857\tmax score 10.00000\n",
            "35 episode\tavg score 1.75000\tmax score -1.00000\n",
            "36 episode\tavg score 1.72973\tmax score 1.00000\n",
            "37 episode\tavg score 1.65789\tmax score -1.00000\n",
            "38 episode\tavg score 1.64103\tmax score 1.00000\n",
            "39 episode\tavg score 1.57500\tmax score -1.00000\n",
            "40 episode\tavg score 1.56098\tmax score 1.00000\n",
            "41 episode\tavg score 1.52381\tmax score 0.00000\n",
            "42 episode\tavg score 1.51163\tmax score 1.00000\n",
            "43 episode\tavg score 1.50000\tmax score 1.00000\n",
            "44 episode\tavg score 1.42222\tmax score -2.00000\n",
            "45 episode\tavg score 1.41304\tmax score 1.00000\n",
            "46 episode\tavg score 1.59574\tmax score 10.00000\n",
            "47 episode\tavg score 1.58333\tmax score 1.00000\n",
            "48 episode\tavg score 1.53061\tmax score -1.00000\n",
            "49 episode\tavg score 1.52000\tmax score 1.00000\n",
            "50 episode\tavg score 1.50980\tmax score 1.00000\n",
            "51 episode\tavg score 1.67308\tmax score 10.00000\n",
            "52 episode\tavg score 1.66038\tmax score 1.00000\n",
            "53 episode\tavg score 1.81481\tmax score 10.00000\n",
            "54 episode\tavg score 1.80000\tmax score 1.00000\n",
            "55 episode\tavg score 1.75000\tmax score -1.00000\n",
            "56 episode\tavg score 1.73684\tmax score 1.00000\n",
            "57 episode\tavg score 1.72414\tmax score 1.00000\n",
            "58 episode\tavg score 1.71186\tmax score 1.00000\n",
            "59 episode\tavg score 1.70000\tmax score 1.00000\n",
            "60 episode\tavg score 1.65574\tmax score -1.00000\n",
            "61 episode\tavg score 1.64516\tmax score 1.00000\n",
            "62 episode\tavg score 1.63492\tmax score 1.00000\n",
            "63 episode\tavg score 1.62500\tmax score 1.00000\n",
            "64 episode\tavg score 1.61538\tmax score 1.00000\n",
            "65 episode\tavg score 1.57576\tmax score -1.00000\n",
            "66 episode\tavg score 1.53731\tmax score -1.00000\n",
            "67 episode\tavg score 1.50000\tmax score -1.00000\n",
            "68 episode\tavg score 1.49275\tmax score 1.00000\n",
            "69 episode\tavg score 1.61429\tmax score 10.00000\n",
            "70 episode\tavg score 1.73239\tmax score 10.00000\n",
            "71 episode\tavg score 1.72222\tmax score 1.00000\n",
            "72 episode\tavg score 1.71233\tmax score 1.00000\n",
            "73 episode\tavg score 1.83784\tmax score 11.00000\n",
            "74 episode\tavg score 1.80000\tmax score -1.00000\n",
            "75 episode\tavg score 1.78947\tmax score 1.00000\n",
            "76 episode\tavg score 1.77922\tmax score 1.00000\n",
            "77 episode\tavg score 1.76923\tmax score 1.00000\n",
            "78 episode\tavg score 1.75949\tmax score 1.00000\n",
            "79 episode\tavg score 1.75000\tmax score 1.00000\n",
            "80 episode\tavg score 1.70370\tmax score -2.00000\n",
            "81 episode\tavg score 1.80488\tmax score 10.00000\n",
            "82 episode\tavg score 1.79518\tmax score 1.00000\n",
            "83 episode\tavg score 1.75000\tmax score -2.00000\n",
            "84 episode\tavg score 1.74118\tmax score 1.00000\n",
            "85 episode\tavg score 1.73256\tmax score 1.00000\n",
            "86 episode\tavg score 1.70115\tmax score -1.00000\n",
            "87 episode\tavg score 1.81818\tmax score 12.00000\n",
            "88 episode\tavg score 1.94382\tmax score 13.00000\n",
            "89 episode\tavg score 1.94444\tmax score 2.00000\n",
            "90 episode\tavg score 1.93407\tmax score 1.00000\n",
            "91 episode\tavg score 1.89130\tmax score -2.00000\n",
            "92 episode\tavg score 1.89247\tmax score 2.00000\n",
            "93 episode\tavg score 1.88298\tmax score 1.00000\n",
            "94 episode\tavg score 1.85263\tmax score -1.00000\n",
            "95 episode\tavg score 1.84375\tmax score 1.00000\n",
            "96 episode\tavg score 1.83505\tmax score 1.00000\n",
            "97 episode\tavg score 1.80612\tmax score -1.00000\n",
            "98 episode\tavg score 1.79798\tmax score 1.00000\n",
            "99 episode\tavg score 1.79000\tmax score 1.00000\n",
            "100 episode\tavg score 1.78000\tmax score 1.00000\n",
            "101 episode\tavg score 1.78000\tmax score 1.00000\n",
            "102 episode\tavg score 1.87000\tmax score 10.00000\n",
            "103 episode\tavg score 1.87000\tmax score 1.00000\n",
            "104 episode\tavg score 1.86000\tmax score 1.00000\n",
            "105 episode\tavg score 1.86000\tmax score 1.00000\n",
            "106 episode\tavg score 1.84000\tmax score -1.00000\n",
            "107 episode\tavg score 1.85000\tmax score 2.00000\n",
            "108 episode\tavg score 1.84000\tmax score 10.00000\n",
            "109 episode\tavg score 1.81000\tmax score -2.00000\n",
            "110 episode\tavg score 1.81000\tmax score 1.00000\n",
            "111 episode\tavg score 1.81000\tmax score 1.00000\n",
            "112 episode\tavg score 1.72000\tmax score 1.00000\n",
            "113 episode\tavg score 1.75000\tmax score 1.00000\n",
            "114 episode\tavg score 1.77000\tmax score 1.00000\n",
            "115 episode\tavg score 1.77000\tmax score 1.00000\n",
            "116 episode\tavg score 1.74000\tmax score -2.00000\n",
            "117 episode\tavg score 1.74000\tmax score 1.00000\n",
            "118 episode\tavg score 1.75000\tmax score -1.00000\n",
            "119 episode\tavg score 1.76000\tmax score -1.00000\n",
            "120 episode\tavg score 1.78000\tmax score 1.00000\n",
            "121 episode\tavg score 1.75000\tmax score -2.00000\n",
            "122 episode\tavg score 1.64000\tmax score -1.00000\n",
            "123 episode\tavg score 1.61000\tmax score -2.00000\n",
            "124 episode\tavg score 1.60000\tmax score -2.00000\n",
            "125 episode\tavg score 1.69000\tmax score 10.00000\n",
            "126 episode\tavg score 1.69000\tmax score 1.00000\n",
            "127 episode\tavg score 1.68000\tmax score -2.00000\n",
            "128 episode\tavg score 1.57000\tmax score -1.00000\n",
            "129 episode\tavg score 1.67000\tmax score 11.00000\n",
            "130 episode\tavg score 1.69000\tmax score 1.00000\n",
            "131 episode\tavg score 1.69000\tmax score 1.00000\n",
            "132 episode\tavg score 1.78000\tmax score 10.00000\n",
            "133 episode\tavg score 1.75000\tmax score -2.00000\n",
            "134 episode\tavg score 1.66000\tmax score 1.00000\n",
            "135 episode\tavg score 1.68000\tmax score 1.00000\n",
            "136 episode\tavg score 1.65000\tmax score -2.00000\n",
            "137 episode\tavg score 1.67000\tmax score 1.00000\n",
            "138 episode\tavg score 1.65000\tmax score -1.00000\n",
            "139 episode\tavg score 1.68000\tmax score 2.00000\n",
            "140 episode\tavg score 1.68000\tmax score 1.00000\n",
            "141 episode\tavg score 1.66000\tmax score -2.00000\n",
            "142 episode\tavg score 1.67000\tmax score 2.00000\n",
            "143 episode\tavg score 1.76000\tmax score 10.00000\n",
            "144 episode\tavg score 1.88000\tmax score 10.00000\n",
            "145 episode\tavg score 1.97000\tmax score 10.00000\n",
            "146 episode\tavg score 1.85000\tmax score -2.00000\n",
            "147 episode\tavg score 1.85000\tmax score 1.00000\n",
            "148 episode\tavg score 1.87000\tmax score 1.00000\n",
            "149 episode\tavg score 1.85000\tmax score -1.00000\n",
            "150 episode\tavg score 1.85000\tmax score 1.00000\n",
            "151 episode\tavg score 1.74000\tmax score -1.00000\n",
            "152 episode\tavg score 1.83000\tmax score 10.00000\n",
            "153 episode\tavg score 1.72000\tmax score -1.00000\n",
            "154 episode\tavg score 1.81000\tmax score 10.00000\n",
            "155 episode\tavg score 1.80000\tmax score -2.00000\n",
            "156 episode\tavg score 1.77000\tmax score -2.00000\n",
            "157 episode\tavg score 1.77000\tmax score 1.00000\n",
            "158 episode\tavg score 1.77000\tmax score 1.00000\n",
            "159 episode\tavg score 1.77000\tmax score 1.00000\n",
            "160 episode\tavg score 1.79000\tmax score 1.00000\n",
            "161 episode\tavg score 1.76000\tmax score -2.00000\n",
            "162 episode\tavg score 1.74000\tmax score -1.00000\n",
            "163 episode\tavg score 1.72000\tmax score -1.00000\n",
            "164 episode\tavg score 1.72000\tmax score 1.00000\n",
            "165 episode\tavg score 1.74000\tmax score 1.00000\n",
            "166 episode\tavg score 1.74000\tmax score -1.00000\n",
            "167 episode\tavg score 1.76000\tmax score 1.00000\n",
            "168 episode\tavg score 1.76000\tmax score 1.00000\n",
            "169 episode\tavg score 1.67000\tmax score 1.00000\n",
            "170 episode\tavg score 1.55000\tmax score -2.00000\n",
            "171 episode\tavg score 1.64000\tmax score 10.00000\n",
            "172 episode\tavg score 1.64000\tmax score 1.00000\n",
            "173 episode\tavg score 1.64000\tmax score 11.00000\n",
            "174 episode\tavg score 1.63000\tmax score -2.00000\n",
            "175 episode\tavg score 1.63000\tmax score 1.00000\n",
            "176 episode\tavg score 1.72000\tmax score 10.00000\n",
            "177 episode\tavg score 1.70000\tmax score -1.00000\n",
            "178 episode\tavg score 1.68000\tmax score -1.00000\n",
            "179 episode\tavg score 1.65000\tmax score -2.00000\n",
            "180 episode\tavg score 1.77000\tmax score 10.00000\n",
            "181 episode\tavg score 1.68000\tmax score 1.00000\n",
            "182 episode\tavg score 1.66000\tmax score -1.00000\n",
            "183 episode\tavg score 1.69000\tmax score 1.00000\n",
            "184 episode\tavg score 1.69000\tmax score 1.00000\n",
            "185 episode\tavg score 1.69000\tmax score 1.00000\n",
            "186 episode\tavg score 1.81000\tmax score 11.00000\n",
            "187 episode\tavg score 1.70000\tmax score 1.00000\n",
            "188 episode\tavg score 1.58000\tmax score 1.00000\n",
            "189 episode\tavg score 1.53000\tmax score -3.00000\n",
            "190 episode\tavg score 1.62000\tmax score 10.00000\n",
            "191 episode\tavg score 1.63000\tmax score -1.00000\n",
            "192 episode\tavg score 1.61000\tmax score 0.00000\n",
            "193 episode\tavg score 1.58000\tmax score -2.00000\n",
            "194 episode\tavg score 1.58000\tmax score -1.00000\n",
            "195 episode\tavg score 1.58000\tmax score 1.00000\n",
            "196 episode\tavg score 1.58000\tmax score 1.00000\n",
            "197 episode\tavg score 1.69000\tmax score 10.00000\n",
            "198 episode\tavg score 1.78000\tmax score 10.00000\n",
            "199 episode\tavg score 1.87000\tmax score 10.00000\n",
            "200 episode\tavg score 1.87000\tmax score 1.00000\n",
            "201 episode\tavg score 1.85000\tmax score -1.00000\n",
            "202 episode\tavg score 1.85000\tmax score 10.00000\n",
            "203 episode\tavg score 1.86000\tmax score 2.00000\n",
            "204 episode\tavg score 1.86000\tmax score 1.00000\n",
            "205 episode\tavg score 1.86000\tmax score 1.00000\n",
            "206 episode\tavg score 1.86000\tmax score -1.00000\n",
            "207 episode\tavg score 1.86000\tmax score 2.00000\n",
            "208 episode\tavg score 1.77000\tmax score 1.00000\n",
            "209 episode\tavg score 1.77000\tmax score -2.00000\n",
            "210 episode\tavg score 1.86000\tmax score 10.00000\n",
            "211 episode\tavg score 1.86000\tmax score 1.00000\n",
            "212 episode\tavg score 1.83000\tmax score -2.00000\n",
            "213 episode\tavg score 1.83000\tmax score 1.00000\n",
            "214 episode\tavg score 1.83000\tmax score 1.00000\n",
            "215 episode\tavg score 1.83000\tmax score 1.00000\n",
            "216 episode\tavg score 1.95000\tmax score 10.00000\n",
            "217 episode\tavg score 1.93000\tmax score -1.00000\n",
            "218 episode\tavg score 1.95000\tmax score 1.00000\n",
            "219 episode\tavg score 1.98000\tmax score 2.00000\n",
            "220 episode\tavg score 1.96000\tmax score -1.00000\n",
            "221 episode\tavg score 1.98000\tmax score 0.00000\n",
            "222 episode\tavg score 2.00000\tmax score 1.00000\n",
            "223 episode\tavg score 2.03000\tmax score 1.00000\n",
            "224 episode\tavg score 2.06000\tmax score 1.00000\n",
            "225 episode\tavg score 1.98000\tmax score 2.00000\n",
            "226 episode\tavg score 1.98000\tmax score 1.00000\n",
            "227 episode\tavg score 2.01000\tmax score 1.00000\n",
            "228 episode\tavg score 2.14000\tmax score 12.00000\n",
            "229 episode\tavg score 2.04000\tmax score 1.00000\n",
            "230 episode\tavg score 2.13000\tmax score 10.00000\n",
            "231 episode\tavg score 2.13000\tmax score 1.00000\n",
            "232 episode\tavg score 2.04000\tmax score 1.00000\n",
            "233 episode\tavg score 2.16000\tmax score 10.00000\n",
            "234 episode\tavg score 2.16000\tmax score 1.00000\n",
            "235 episode\tavg score 2.16000\tmax score 1.00000\n",
            "236 episode\tavg score 2.17000\tmax score -1.00000\n",
            "237 episode\tavg score 2.26000\tmax score 10.00000\n",
            "238 episode\tavg score 2.28000\tmax score 1.00000\n",
            "239 episode\tavg score 2.36000\tmax score 10.00000\n",
            "240 episode\tavg score 2.36000\tmax score 1.00000\n",
            "241 episode\tavg score 2.39000\tmax score 1.00000\n",
            "242 episode\tavg score 2.38000\tmax score 1.00000\n",
            "243 episode\tavg score 2.29000\tmax score 1.00000\n",
            "244 episode\tavg score 2.30000\tmax score 11.00000\n",
            "245 episode\tavg score 2.21000\tmax score 1.00000\n",
            "246 episode\tavg score 2.24000\tmax score 1.00000\n",
            "247 episode\tavg score 2.24000\tmax score 1.00000\n",
            "248 episode\tavg score 2.24000\tmax score 1.00000\n",
            "249 episode\tavg score 2.27000\tmax score 2.00000\n",
            "250 episode\tavg score 2.25000\tmax score -1.00000\n",
            "251 episode\tavg score 2.25000\tmax score -1.00000\n",
            "252 episode\tavg score 2.16000\tmax score 1.00000\n",
            "253 episode\tavg score 2.15000\tmax score -2.00000\n",
            "254 episode\tavg score 2.06000\tmax score 1.00000\n",
            "255 episode\tavg score 2.18000\tmax score 10.00000\n",
            "256 episode\tavg score 2.18000\tmax score -2.00000\n",
            "257 episode\tavg score 2.18000\tmax score 1.00000\n",
            "258 episode\tavg score 2.18000\tmax score 1.00000\n",
            "259 episode\tavg score 2.18000\tmax score 1.00000\n",
            "260 episode\tavg score 2.18000\tmax score 1.00000\n",
            "261 episode\tavg score 2.21000\tmax score 1.00000\n",
            "262 episode\tavg score 2.23000\tmax score 1.00000\n",
            "263 episode\tavg score 2.25000\tmax score 1.00000\n",
            "264 episode\tavg score 2.34000\tmax score 10.00000\n",
            "265 episode\tavg score 2.31000\tmax score -2.00000\n",
            "266 episode\tavg score 2.42000\tmax score 10.00000\n",
            "267 episode\tavg score 2.51000\tmax score 10.00000\n",
            "268 episode\tavg score 2.51000\tmax score 1.00000\n",
            "269 episode\tavg score 2.51000\tmax score 1.00000\n",
            "270 episode\tavg score 2.63000\tmax score 10.00000\n",
            "271 episode\tavg score 2.51000\tmax score -2.00000\n",
            "272 episode\tavg score 2.51000\tmax score 1.00000\n",
            "273 episode\tavg score 2.41000\tmax score 1.00000\n",
            "274 episode\tavg score 2.44000\tmax score 1.00000\n",
            "275 episode\tavg score 2.45000\tmax score 2.00000\n",
            "276 episode\tavg score 2.36000\tmax score 1.00000\n",
            "277 episode\tavg score 2.38000\tmax score 1.00000\n",
            "278 episode\tavg score 2.40000\tmax score 1.00000\n",
            "279 episode\tavg score 2.40000\tmax score -2.00000\n",
            "280 episode\tavg score 2.31000\tmax score 1.00000\n",
            "281 episode\tavg score 2.31000\tmax score 1.00000\n",
            "282 episode\tavg score 2.33000\tmax score 1.00000\n",
            "283 episode\tavg score 2.33000\tmax score 1.00000\n",
            "284 episode\tavg score 2.33000\tmax score 1.00000\n",
            "285 episode\tavg score 2.33000\tmax score 1.00000\n",
            "286 episode\tavg score 2.23000\tmax score 1.00000\n",
            "287 episode\tavg score 2.23000\tmax score 1.00000\n",
            "288 episode\tavg score 2.20000\tmax score -2.00000\n",
            "289 episode\tavg score 2.24000\tmax score 1.00000\n",
            "290 episode\tavg score 2.15000\tmax score 1.00000\n",
            "291 episode\tavg score 2.14000\tmax score -2.00000\n",
            "292 episode\tavg score 2.24000\tmax score 10.00000\n",
            "293 episode\tavg score 2.27000\tmax score 1.00000\n",
            "294 episode\tavg score 2.29000\tmax score 1.00000\n",
            "295 episode\tavg score 2.29000\tmax score 1.00000\n",
            "296 episode\tavg score 2.38000\tmax score 10.00000\n",
            "297 episode\tavg score 2.29000\tmax score 1.00000\n",
            "298 episode\tavg score 2.20000\tmax score 1.00000\n",
            "299 episode\tavg score 2.11000\tmax score 1.00000\n",
            "300 episode\tavg score 2.11000\tmax score 1.00000\n",
            "301 episode\tavg score 2.13000\tmax score 1.00000\n",
            "302 episode\tavg score 2.04000\tmax score 1.00000\n",
            "303 episode\tavg score 2.13000\tmax score 11.00000\n",
            "304 episode\tavg score 2.13000\tmax score 1.00000\n",
            "305 episode\tavg score 2.13000\tmax score 1.00000\n",
            "306 episode\tavg score 2.16000\tmax score 2.00000\n",
            "307 episode\tavg score 2.15000\tmax score 1.00000\n",
            "308 episode\tavg score 2.15000\tmax score 1.00000\n",
            "309 episode\tavg score 2.27000\tmax score 10.00000\n",
            "310 episode\tavg score 2.18000\tmax score 1.00000\n",
            "311 episode\tavg score 2.18000\tmax score 1.00000\n",
            "312 episode\tavg score 2.21000\tmax score 1.00000\n",
            "313 episode\tavg score 2.21000\tmax score 1.00000\n",
            "314 episode\tavg score 2.21000\tmax score 1.00000\n",
            "315 episode\tavg score 2.21000\tmax score 1.00000\n",
            "316 episode\tavg score 2.22000\tmax score 11.00000\n",
            "317 episode\tavg score 2.24000\tmax score 1.00000\n",
            "318 episode\tavg score 2.24000\tmax score 1.00000\n",
            "319 episode\tavg score 2.20000\tmax score -2.00000\n",
            "320 episode\tavg score 2.22000\tmax score 1.00000\n",
            "321 episode\tavg score 2.32000\tmax score 10.00000\n",
            "322 episode\tavg score 2.33000\tmax score 2.00000\n",
            "323 episode\tavg score 2.33000\tmax score 1.00000\n",
            "324 episode\tavg score 2.33000\tmax score 1.00000\n",
            "325 episode\tavg score 2.32000\tmax score 1.00000\n",
            "326 episode\tavg score 2.32000\tmax score 1.00000\n",
            "327 episode\tavg score 2.32000\tmax score 1.00000\n",
            "328 episode\tavg score 2.21000\tmax score 1.00000\n",
            "329 episode\tavg score 2.21000\tmax score 1.00000\n",
            "330 episode\tavg score 2.09000\tmax score -2.00000\n",
            "331 episode\tavg score 2.18000\tmax score 10.00000\n",
            "332 episode\tavg score 2.18000\tmax score 1.00000\n",
            "333 episode\tavg score 2.09000\tmax score 1.00000\n",
            "334 episode\tavg score 2.09000\tmax score 1.00000\n",
            "335 episode\tavg score 2.19000\tmax score 11.00000\n",
            "336 episode\tavg score 2.21000\tmax score 1.00000\n",
            "337 episode\tavg score 2.11000\tmax score 0.00000\n",
            "338 episode\tavg score 2.20000\tmax score 10.00000\n",
            "339 episode\tavg score 2.11000\tmax score 1.00000\n",
            "340 episode\tavg score 2.09000\tmax score -1.00000\n",
            "341 episode\tavg score 2.19000\tmax score 11.00000\n",
            "342 episode\tavg score 2.19000\tmax score 1.00000\n",
            "343 episode\tavg score 2.19000\tmax score 1.00000\n",
            "344 episode\tavg score 2.09000\tmax score 1.00000\n",
            "345 episode\tavg score 2.09000\tmax score 1.00000\n",
            "346 episode\tavg score 2.09000\tmax score 1.00000\n",
            "347 episode\tavg score 2.09000\tmax score 1.00000\n",
            "348 episode\tavg score 2.09000\tmax score 1.00000\n",
            "349 episode\tavg score 2.08000\tmax score 1.00000\n",
            "350 episode\tavg score 2.10000\tmax score 1.00000\n",
            "351 episode\tavg score 2.13000\tmax score 2.00000\n",
            "352 episode\tavg score 2.11000\tmax score -1.00000\n",
            "353 episode\tavg score 2.14000\tmax score 1.00000\n",
            "354 episode\tavg score 2.14000\tmax score 1.00000\n",
            "355 episode\tavg score 2.05000\tmax score 1.00000\n",
            "356 episode\tavg score 2.18000\tmax score 11.00000\n",
            "357 episode\tavg score 2.18000\tmax score 1.00000\n",
            "358 episode\tavg score 2.16000\tmax score -1.00000\n",
            "359 episode\tavg score 2.16000\tmax score 1.00000\n",
            "360 episode\tavg score 2.13000\tmax score -2.00000\n",
            "361 episode\tavg score 2.13000\tmax score 1.00000\n",
            "362 episode\tavg score 2.12000\tmax score 0.00000\n",
            "363 episode\tavg score 2.12000\tmax score 1.00000\n",
            "364 episode\tavg score 2.03000\tmax score 1.00000\n",
            "365 episode\tavg score 2.06000\tmax score 1.00000\n",
            "366 episode\tavg score 1.97000\tmax score 1.00000\n",
            "367 episode\tavg score 1.89000\tmax score 2.00000\n",
            "368 episode\tavg score 1.99000\tmax score 11.00000\n",
            "369 episode\tavg score 1.99000\tmax score 1.00000\n",
            "370 episode\tavg score 1.88000\tmax score -1.00000\n",
            "371 episode\tavg score 1.92000\tmax score 2.00000\n",
            "372 episode\tavg score 2.03000\tmax score 12.00000\n",
            "373 episode\tavg score 2.12000\tmax score 10.00000\n",
            "374 episode\tavg score 2.12000\tmax score 1.00000\n",
            "375 episode\tavg score 2.20000\tmax score 10.00000\n",
            "376 episode\tavg score 2.31000\tmax score 12.00000\n",
            "377 episode\tavg score 2.31000\tmax score 1.00000\n",
            "378 episode\tavg score 2.31000\tmax score 1.00000\n",
            "379 episode\tavg score 2.34000\tmax score 1.00000\n",
            "380 episode\tavg score 2.43000\tmax score 10.00000\n",
            "381 episode\tavg score 2.43000\tmax score 1.00000\n",
            "382 episode\tavg score 2.43000\tmax score 1.00000\n",
            "383 episode\tavg score 2.43000\tmax score 1.00000\n",
            "384 episode\tavg score 2.43000\tmax score 1.00000\n",
            "385 episode\tavg score 2.43000\tmax score 1.00000\n",
            "386 episode\tavg score 2.43000\tmax score 1.00000\n",
            "387 episode\tavg score 2.43000\tmax score 1.00000\n",
            "388 episode\tavg score 2.46000\tmax score 1.00000\n",
            "389 episode\tavg score 2.43000\tmax score -2.00000\n",
            "390 episode\tavg score 2.43000\tmax score 1.00000\n",
            "391 episode\tavg score 2.46000\tmax score 1.00000\n",
            "392 episode\tavg score 2.37000\tmax score 1.00000\n",
            "393 episode\tavg score 2.37000\tmax score 1.00000\n",
            "394 episode\tavg score 2.37000\tmax score 1.00000\n",
            "395 episode\tavg score 2.37000\tmax score 1.00000\n",
            "396 episode\tavg score 2.28000\tmax score 1.00000\n",
            "397 episode\tavg score 2.28000\tmax score 1.00000\n",
            "398 episode\tavg score 2.28000\tmax score 1.00000\n",
            "399 episode\tavg score 2.28000\tmax score 1.00000\n",
            "400 episode\tavg score 2.37000\tmax score 10.00000\n",
            "401 episode\tavg score 2.37000\tmax score 1.00000\n",
            "402 episode\tavg score 2.37000\tmax score 1.00000\n",
            "403 episode\tavg score 2.27000\tmax score 1.00000\n",
            "404 episode\tavg score 2.27000\tmax score 1.00000\n",
            "405 episode\tavg score 2.28000\tmax score 2.00000\n",
            "406 episode\tavg score 2.27000\tmax score 1.00000\n",
            "407 episode\tavg score 2.24000\tmax score -2.00000\n",
            "408 episode\tavg score 2.24000\tmax score 1.00000\n",
            "409 episode\tavg score 2.15000\tmax score 1.00000\n",
            "410 episode\tavg score 2.15000\tmax score 1.00000\n",
            "411 episode\tavg score 2.15000\tmax score 1.00000\n",
            "412 episode\tavg score 2.24000\tmax score 10.00000\n",
            "413 episode\tavg score 2.24000\tmax score 1.00000\n",
            "414 episode\tavg score 2.24000\tmax score 1.00000\n",
            "415 episode\tavg score 2.23000\tmax score 0.00000\n",
            "416 episode\tavg score 2.22000\tmax score 10.00000\n",
            "417 episode\tavg score 2.22000\tmax score 1.00000\n",
            "418 episode\tavg score 2.22000\tmax score 1.00000\n",
            "419 episode\tavg score 2.36000\tmax score 12.00000\n",
            "420 episode\tavg score 2.36000\tmax score 1.00000\n",
            "421 episode\tavg score 2.27000\tmax score 1.00000\n",
            "422 episode\tavg score 2.23000\tmax score -2.00000\n",
            "423 episode\tavg score 2.23000\tmax score 1.00000\n",
            "424 episode\tavg score 2.23000\tmax score 1.00000\n",
            "425 episode\tavg score 2.32000\tmax score 10.00000\n",
            "426 episode\tavg score 2.41000\tmax score 10.00000\n",
            "427 episode\tavg score 2.41000\tmax score 1.00000\n",
            "428 episode\tavg score 2.42000\tmax score 2.00000\n",
            "429 episode\tavg score 2.40000\tmax score -1.00000\n",
            "430 episode\tavg score 2.43000\tmax score 1.00000\n",
            "431 episode\tavg score 2.34000\tmax score 1.00000\n",
            "432 episode\tavg score 2.34000\tmax score 1.00000\n",
            "433 episode\tavg score 2.34000\tmax score 1.00000\n",
            "434 episode\tavg score 2.34000\tmax score 1.00000\n",
            "435 episode\tavg score 2.24000\tmax score 1.00000\n",
            "436 episode\tavg score 2.24000\tmax score 1.00000\n",
            "437 episode\tavg score 2.25000\tmax score 1.00000\n",
            "438 episode\tavg score 2.16000\tmax score 1.00000\n",
            "439 episode\tavg score 2.16000\tmax score 1.00000\n",
            "440 episode\tavg score 2.18000\tmax score 1.00000\n",
            "441 episode\tavg score 2.09000\tmax score 2.00000\n",
            "442 episode\tavg score 2.10000\tmax score 2.00000\n",
            "443 episode\tavg score 2.11000\tmax score 2.00000\n",
            "444 episode\tavg score 2.11000\tmax score 1.00000\n",
            "445 episode\tavg score 2.11000\tmax score 1.00000\n",
            "446 episode\tavg score 2.20000\tmax score 10.00000\n",
            "447 episode\tavg score 2.20000\tmax score 1.00000\n",
            "448 episode\tavg score 2.20000\tmax score 1.00000\n",
            "449 episode\tavg score 2.29000\tmax score 10.00000\n",
            "450 episode\tavg score 2.26000\tmax score -2.00000\n",
            "451 episode\tavg score 2.25000\tmax score 1.00000\n",
            "452 episode\tavg score 2.27000\tmax score 1.00000\n",
            "453 episode\tavg score 2.28000\tmax score 2.00000\n",
            "454 episode\tavg score 2.28000\tmax score 1.00000\n",
            "455 episode\tavg score 2.28000\tmax score 1.00000\n",
            "456 episode\tavg score 2.18000\tmax score 1.00000\n",
            "457 episode\tavg score 2.16000\tmax score -1.00000\n",
            "458 episode\tavg score 2.18000\tmax score 1.00000\n",
            "459 episode\tavg score 2.19000\tmax score 2.00000\n",
            "460 episode\tavg score 2.23000\tmax score 2.00000\n",
            "461 episode\tavg score 2.23000\tmax score 1.00000\n",
            "462 episode\tavg score 2.22000\tmax score -1.00000\n",
            "463 episode\tavg score 2.22000\tmax score 1.00000\n",
            "464 episode\tavg score 2.22000\tmax score 1.00000\n",
            "465 episode\tavg score 2.32000\tmax score 11.00000\n",
            "466 episode\tavg score 2.32000\tmax score 1.00000\n",
            "467 episode\tavg score 2.28000\tmax score -2.00000\n",
            "468 episode\tavg score 2.18000\tmax score 1.00000\n",
            "469 episode\tavg score 2.19000\tmax score 2.00000\n",
            "470 episode\tavg score 2.32000\tmax score 12.00000\n",
            "471 episode\tavg score 2.29000\tmax score -1.00000\n",
            "472 episode\tavg score 2.18000\tmax score 1.00000\n",
            "473 episode\tavg score 2.09000\tmax score 1.00000\n",
            "474 episode\tavg score 2.09000\tmax score 1.00000\n",
            "475 episode\tavg score 2.00000\tmax score 1.00000\n",
            "476 episode\tavg score 1.89000\tmax score 1.00000\n",
            "477 episode\tavg score 1.89000\tmax score 1.00000\n",
            "478 episode\tavg score 1.89000\tmax score 1.00000\n",
            "479 episode\tavg score 1.86000\tmax score -2.00000\n",
            "480 episode\tavg score 1.77000\tmax score 1.00000\n",
            "481 episode\tavg score 1.77000\tmax score 1.00000\n",
            "482 episode\tavg score 1.78000\tmax score 2.00000\n",
            "483 episode\tavg score 1.77000\tmax score 0.00000\n",
            "484 episode\tavg score 1.86000\tmax score 10.00000\n",
            "485 episode\tavg score 1.97000\tmax score 12.00000\n",
            "486 episode\tavg score 1.97000\tmax score 1.00000\n",
            "487 episode\tavg score 2.06000\tmax score 10.00000\n",
            "488 episode\tavg score 2.07000\tmax score 2.00000\n",
            "489 episode\tavg score 2.19000\tmax score 10.00000\n",
            "490 episode\tavg score 2.19000\tmax score 1.00000\n",
            "491 episode\tavg score 2.19000\tmax score 1.00000\n",
            "492 episode\tavg score 2.19000\tmax score 1.00000\n",
            "493 episode\tavg score 2.29000\tmax score 11.00000\n",
            "494 episode\tavg score 2.29000\tmax score 1.00000\n",
            "495 episode\tavg score 2.38000\tmax score 10.00000\n",
            "496 episode\tavg score 2.38000\tmax score 1.00000\n",
            "497 episode\tavg score 2.38000\tmax score 1.00000\n",
            "498 episode\tavg score 2.36000\tmax score -1.00000\n",
            "499 episode\tavg score 2.36000\tmax score 1.00000\n",
            "500 episode\tavg score 2.27000\tmax score 1.00000\n",
            "501 episode\tavg score 2.27000\tmax score 1.00000\n",
            "502 episode\tavg score 2.36000\tmax score 10.00000\n",
            "503 episode\tavg score 2.33000\tmax score -2.00000\n",
            "504 episode\tavg score 2.42000\tmax score 10.00000\n",
            "505 episode\tavg score 2.51000\tmax score 11.00000\n",
            "506 episode\tavg score 2.51000\tmax score 1.00000\n",
            "507 episode\tavg score 2.56000\tmax score 3.00000\n",
            "508 episode\tavg score 2.66000\tmax score 11.00000\n",
            "509 episode\tavg score 2.64000\tmax score -1.00000\n",
            "510 episode\tavg score 2.74000\tmax score 11.00000\n",
            "511 episode\tavg score 2.74000\tmax score 1.00000\n",
            "512 episode\tavg score 2.74000\tmax score 10.00000\n",
            "513 episode\tavg score 2.74000\tmax score 1.00000\n",
            "514 episode\tavg score 2.74000\tmax score 1.00000\n",
            "515 episode\tavg score 2.84000\tmax score 10.00000\n",
            "516 episode\tavg score 2.75000\tmax score 1.00000\n",
            "517 episode\tavg score 2.75000\tmax score 1.00000\n",
            "518 episode\tavg score 2.75000\tmax score 1.00000\n",
            "519 episode\tavg score 2.64000\tmax score 1.00000\n",
            "520 episode\tavg score 2.64000\tmax score 1.00000\n",
            "521 episode\tavg score 2.64000\tmax score 1.00000\n",
            "522 episode\tavg score 2.69000\tmax score 3.00000\n",
            "523 episode\tavg score 2.79000\tmax score 11.00000\n",
            "524 episode\tavg score 2.79000\tmax score 1.00000\n",
            "525 episode\tavg score 2.79000\tmax score 10.00000\n",
            "526 episode\tavg score 2.71000\tmax score 2.00000\n",
            "527 episode\tavg score 2.69000\tmax score -1.00000\n",
            "528 episode\tavg score 2.68000\tmax score 1.00000\n",
            "529 episode\tavg score 2.70000\tmax score 1.00000\n",
            "530 episode\tavg score 2.70000\tmax score 1.00000\n",
            "531 episode\tavg score 2.71000\tmax score 2.00000\n",
            "532 episode\tavg score 2.71000\tmax score 1.00000\n",
            "533 episode\tavg score 2.80000\tmax score 10.00000\n",
            "534 episode\tavg score 2.80000\tmax score 1.00000\n",
            "535 episode\tavg score 2.80000\tmax score 1.00000\n",
            "536 episode\tavg score 2.80000\tmax score 1.00000\n",
            "537 episode\tavg score 2.80000\tmax score 1.00000\n",
            "538 episode\tavg score 2.91000\tmax score 12.00000\n",
            "539 episode\tavg score 2.88000\tmax score -2.00000\n",
            "540 episode\tavg score 2.99000\tmax score 12.00000\n",
            "541 episode\tavg score 2.98000\tmax score 1.00000\n",
            "542 episode\tavg score 3.08000\tmax score 12.00000\n",
            "543 episode\tavg score 3.07000\tmax score 1.00000\n",
            "544 episode\tavg score 3.07000\tmax score 1.00000\n",
            "545 episode\tavg score 3.16000\tmax score 10.00000\n",
            "546 episode\tavg score 3.16000\tmax score 10.00000\n",
            "547 episode\tavg score 3.17000\tmax score 2.00000\n",
            "548 episode\tavg score 3.28000\tmax score 12.00000\n",
            "549 episode\tavg score 3.19000\tmax score 1.00000\n",
            "550 episode\tavg score 3.22000\tmax score 1.00000\n",
            "551 episode\tavg score 3.22000\tmax score 1.00000\n",
            "552 episode\tavg score 3.19000\tmax score -2.00000\n",
            "553 episode\tavg score 3.18000\tmax score 1.00000\n",
            "554 episode\tavg score 3.19000\tmax score 2.00000\n",
            "555 episode\tavg score 3.19000\tmax score 1.00000\n",
            "556 episode\tavg score 3.29000\tmax score 11.00000\n",
            "557 episode\tavg score 3.31000\tmax score 1.00000\n",
            "558 episode\tavg score 3.33000\tmax score 3.00000\n",
            "559 episode\tavg score 3.32000\tmax score 1.00000\n",
            "560 episode\tavg score 3.31000\tmax score 1.00000\n",
            "561 episode\tavg score 3.31000\tmax score 1.00000\n",
            "562 episode\tavg score 3.33000\tmax score 1.00000\n",
            "563 episode\tavg score 3.34000\tmax score 2.00000\n",
            "564 episode\tavg score 3.35000\tmax score 2.00000\n",
            "565 episode\tavg score 3.22000\tmax score -2.00000\n",
            "566 episode\tavg score 3.24000\tmax score 3.00000\n",
            "567 episode\tavg score 3.27000\tmax score 1.00000\n",
            "568 episode\tavg score 3.27000\tmax score 1.00000\n",
            "569 episode\tavg score 3.37000\tmax score 12.00000\n",
            "570 episode\tavg score 3.26000\tmax score 1.00000\n",
            "571 episode\tavg score 3.39000\tmax score 12.00000\n",
            "572 episode\tavg score 3.40000\tmax score 2.00000\n",
            "573 episode\tavg score 3.40000\tmax score 1.00000\n",
            "574 episode\tavg score 3.40000\tmax score 1.00000\n",
            "575 episode\tavg score 3.40000\tmax score 1.00000\n",
            "576 episode\tavg score 3.49000\tmax score 10.00000\n",
            "577 episode\tavg score 3.60000\tmax score 12.00000\n",
            "578 episode\tavg score 3.60000\tmax score 1.00000\n",
            "579 episode\tavg score 3.72000\tmax score 10.00000\n",
            "580 episode\tavg score 3.72000\tmax score 1.00000\n",
            "581 episode\tavg score 3.72000\tmax score 1.00000\n",
            "582 episode\tavg score 3.71000\tmax score 1.00000\n",
            "583 episode\tavg score 3.72000\tmax score 1.00000\n",
            "584 episode\tavg score 3.63000\tmax score 1.00000\n",
            "585 episode\tavg score 3.52000\tmax score 1.00000\n",
            "586 episode\tavg score 3.52000\tmax score 1.00000\n",
            "587 episode\tavg score 3.52000\tmax score 10.00000\n",
            "588 episode\tavg score 3.52000\tmax score 2.00000\n",
            "589 episode\tavg score 3.44000\tmax score 2.00000\n",
            "590 episode\tavg score 3.44000\tmax score 1.00000\n",
            "591 episode\tavg score 3.53000\tmax score 10.00000\n",
            "592 episode\tavg score 3.53000\tmax score 1.00000\n",
            "593 episode\tavg score 3.43000\tmax score 1.00000\n",
            "594 episode\tavg score 3.43000\tmax score 1.00000\n",
            "595 episode\tavg score 3.34000\tmax score 1.00000\n",
            "596 episode\tavg score 3.34000\tmax score 1.00000\n",
            "597 episode\tavg score 3.44000\tmax score 11.00000\n",
            "598 episode\tavg score 3.57000\tmax score 12.00000\n",
            "599 episode\tavg score 3.57000\tmax score 1.00000\n",
            "600 episode\tavg score 3.57000\tmax score 1.00000\n",
            "601 episode\tavg score 3.59000\tmax score 3.00000\n",
            "602 episode\tavg score 3.50000\tmax score 1.00000\n",
            "603 episode\tavg score 3.53000\tmax score 1.00000\n",
            "604 episode\tavg score 3.44000\tmax score 1.00000\n",
            "605 episode\tavg score 3.34000\tmax score 1.00000\n",
            "606 episode\tavg score 3.34000\tmax score 1.00000\n",
            "607 episode\tavg score 3.32000\tmax score 1.00000\n",
            "608 episode\tavg score 3.22000\tmax score 1.00000\n",
            "609 episode\tavg score 3.24000\tmax score 1.00000\n",
            "610 episode\tavg score 3.14000\tmax score 1.00000\n",
            "611 episode\tavg score 3.14000\tmax score 1.00000\n",
            "612 episode\tavg score 3.05000\tmax score 1.00000\n",
            "613 episode\tavg score 3.05000\tmax score 1.00000\n",
            "614 episode\tavg score 3.02000\tmax score -2.00000\n",
            "615 episode\tavg score 3.02000\tmax score 10.00000\n",
            "616 episode\tavg score 3.02000\tmax score 1.00000\n",
            "617 episode\tavg score 3.02000\tmax score 1.00000\n",
            "618 episode\tavg score 3.12000\tmax score 11.00000\n",
            "619 episode\tavg score 3.12000\tmax score 1.00000\n",
            "620 episode\tavg score 3.22000\tmax score 11.00000\n",
            "621 episode\tavg score 3.22000\tmax score 1.00000\n",
            "622 episode\tavg score 3.21000\tmax score 2.00000\n",
            "623 episode\tavg score 3.11000\tmax score 1.00000\n",
            "624 episode\tavg score 3.11000\tmax score 1.00000\n",
            "625 episode\tavg score 3.02000\tmax score 1.00000\n",
            "626 episode\tavg score 3.02000\tmax score 2.00000\n",
            "627 episode\tavg score 3.04000\tmax score 1.00000\n",
            "628 episode\tavg score 3.04000\tmax score 1.00000\n",
            "629 episode\tavg score 3.06000\tmax score 3.00000\n",
            "630 episode\tavg score 3.17000\tmax score 12.00000\n",
            "631 episode\tavg score 3.13000\tmax score -2.00000\n",
            "632 episode\tavg score 3.23000\tmax score 11.00000\n",
            "633 episode\tavg score 3.14000\tmax score 1.00000\n",
            "634 episode\tavg score 3.14000\tmax score 1.00000\n",
            "635 episode\tavg score 3.24000\tmax score 11.00000\n",
            "636 episode\tavg score 3.24000\tmax score 1.00000\n",
            "637 episode\tavg score 3.21000\tmax score -2.00000\n",
            "638 episode\tavg score 3.10000\tmax score 1.00000\n",
            "639 episode\tavg score 3.22000\tmax score 10.00000\n",
            "640 episode\tavg score 3.12000\tmax score 2.00000\n",
            "641 episode\tavg score 3.12000\tmax score 1.00000\n",
            "642 episode\tavg score 3.01000\tmax score 1.00000\n",
            "643 episode\tavg score 3.01000\tmax score 1.00000\n",
            "644 episode\tavg score 3.01000\tmax score 1.00000\n",
            "645 episode\tavg score 3.02000\tmax score 11.00000\n",
            "646 episode\tavg score 2.93000\tmax score 1.00000\n",
            "647 episode\tavg score 2.92000\tmax score 1.00000\n",
            "648 episode\tavg score 2.91000\tmax score 11.00000\n",
            "649 episode\tavg score 3.00000\tmax score 10.00000\n",
            "650 episode\tavg score 3.02000\tmax score 3.00000\n",
            "651 episode\tavg score 3.12000\tmax score 11.00000\n",
            "652 episode\tavg score 3.15000\tmax score 1.00000\n",
            "653 episode\tavg score 3.15000\tmax score 1.00000\n",
            "654 episode\tavg score 3.14000\tmax score 1.00000\n",
            "655 episode\tavg score 3.15000\tmax score 2.00000\n",
            "656 episode\tavg score 3.06000\tmax score 2.00000\n",
            "657 episode\tavg score 3.03000\tmax score -2.00000\n",
            "658 episode\tavg score 3.01000\tmax score 1.00000\n",
            "659 episode\tavg score 3.01000\tmax score 1.00000\n",
            "660 episode\tavg score 3.01000\tmax score 1.00000\n",
            "661 episode\tavg score 3.01000\tmax score 1.00000\n",
            "662 episode\tavg score 3.11000\tmax score 11.00000\n",
            "663 episode\tavg score 3.10000\tmax score 1.00000\n",
            "664 episode\tavg score 3.19000\tmax score 11.00000\n",
            "665 episode\tavg score 3.24000\tmax score 3.00000\n",
            "666 episode\tavg score 3.22000\tmax score 1.00000\n",
            "667 episode\tavg score 3.22000\tmax score 1.00000\n",
            "668 episode\tavg score 3.22000\tmax score 1.00000\n",
            "669 episode\tavg score 3.11000\tmax score 1.00000\n",
            "670 episode\tavg score 3.11000\tmax score 1.00000\n",
            "671 episode\tavg score 3.00000\tmax score 1.00000\n",
            "672 episode\tavg score 2.99000\tmax score 1.00000\n",
            "673 episode\tavg score 3.08000\tmax score 10.00000\n",
            "674 episode\tavg score 3.08000\tmax score 1.00000\n",
            "675 episode\tavg score 3.08000\tmax score 1.00000\n",
            "676 episode\tavg score 3.08000\tmax score 10.00000\n",
            "677 episode\tavg score 2.97000\tmax score 1.00000\n",
            "678 episode\tavg score 3.07000\tmax score 11.00000\n",
            "679 episode\tavg score 2.98000\tmax score 1.00000\n",
            "680 episode\tavg score 2.98000\tmax score 1.00000\n",
            "681 episode\tavg score 2.98000\tmax score 1.00000\n",
            "682 episode\tavg score 2.98000\tmax score 1.00000\n",
            "683 episode\tavg score 2.98000\tmax score 1.00000\n",
            "684 episode\tavg score 3.08000\tmax score 11.00000\n",
            "685 episode\tavg score 3.08000\tmax score 1.00000\n",
            "686 episode\tavg score 3.08000\tmax score 1.00000\n",
            "687 episode\tavg score 3.08000\tmax score 10.00000\n",
            "688 episode\tavg score 3.07000\tmax score 1.00000\n",
            "689 episode\tavg score 3.06000\tmax score 1.00000\n",
            "690 episode\tavg score 3.06000\tmax score 1.00000\n",
            "691 episode\tavg score 2.97000\tmax score 1.00000\n",
            "692 episode\tavg score 2.97000\tmax score 1.00000\n",
            "693 episode\tavg score 2.97000\tmax score 1.00000\n",
            "694 episode\tavg score 2.98000\tmax score 2.00000\n",
            "695 episode\tavg score 2.98000\tmax score 1.00000\n",
            "696 episode\tavg score 2.98000\tmax score 1.00000\n",
            "697 episode\tavg score 2.99000\tmax score 12.00000\n",
            "698 episode\tavg score 2.90000\tmax score 3.00000\n",
            "699 episode\tavg score 2.99000\tmax score 10.00000\n",
            "700 episode\tavg score 2.99000\tmax score 1.00000\n",
            "701 episode\tavg score 2.97000\tmax score 1.00000\n",
            "702 episode\tavg score 2.94000\tmax score -2.00000\n",
            "703 episode\tavg score 2.95000\tmax score 2.00000\n",
            "704 episode\tavg score 3.06000\tmax score 12.00000\n",
            "705 episode\tavg score 3.15000\tmax score 10.00000\n",
            "706 episode\tavg score 3.15000\tmax score 1.00000\n",
            "707 episode\tavg score 3.16000\tmax score 2.00000\n",
            "708 episode\tavg score 3.16000\tmax score 1.00000\n",
            "709 episode\tavg score 3.16000\tmax score 1.00000\n",
            "710 episode\tavg score 3.16000\tmax score 1.00000\n",
            "711 episode\tavg score 3.16000\tmax score 1.00000\n",
            "712 episode\tavg score 3.16000\tmax score 1.00000\n",
            "713 episode\tavg score 3.16000\tmax score 1.00000\n",
            "714 episode\tavg score 3.19000\tmax score 1.00000\n",
            "715 episode\tavg score 3.19000\tmax score 10.00000\n",
            "716 episode\tavg score 3.19000\tmax score 1.00000\n",
            "717 episode\tavg score 3.20000\tmax score 2.00000\n",
            "718 episode\tavg score 3.11000\tmax score 2.00000\n",
            "719 episode\tavg score 3.11000\tmax score 1.00000\n",
            "720 episode\tavg score 3.10000\tmax score 10.00000\n",
            "721 episode\tavg score 3.11000\tmax score 2.00000\n",
            "722 episode\tavg score 3.20000\tmax score 11.00000\n",
            "723 episode\tavg score 3.20000\tmax score 1.00000\n",
            "724 episode\tavg score 3.20000\tmax score 1.00000\n",
            "725 episode\tavg score 3.29000\tmax score 10.00000\n",
            "726 episode\tavg score 3.28000\tmax score 1.00000\n",
            "727 episode\tavg score 3.38000\tmax score 11.00000\n",
            "728 episode\tavg score 3.38000\tmax score 1.00000\n",
            "729 episode\tavg score 3.36000\tmax score 1.00000\n",
            "730 episode\tavg score 3.25000\tmax score 1.00000\n",
            "731 episode\tavg score 3.38000\tmax score 11.00000\n",
            "732 episode\tavg score 3.28000\tmax score 1.00000\n",
            "733 episode\tavg score 3.29000\tmax score 2.00000\n",
            "734 episode\tavg score 3.39000\tmax score 11.00000\n",
            "735 episode\tavg score 3.29000\tmax score 1.00000\n",
            "736 episode\tavg score 3.40000\tmax score 12.00000\n",
            "737 episode\tavg score 3.43000\tmax score 1.00000\n",
            "738 episode\tavg score 3.43000\tmax score 1.00000\n",
            "739 episode\tavg score 3.34000\tmax score 1.00000\n",
            "740 episode\tavg score 3.33000\tmax score 1.00000\n",
            "741 episode\tavg score 3.33000\tmax score 1.00000\n",
            "742 episode\tavg score 3.33000\tmax score 1.00000\n",
            "743 episode\tavg score 3.43000\tmax score 11.00000\n",
            "744 episode\tavg score 3.43000\tmax score 1.00000\n",
            "745 episode\tavg score 3.33000\tmax score 1.00000\n",
            "746 episode\tavg score 3.33000\tmax score 1.00000\n",
            "747 episode\tavg score 3.33000\tmax score 1.00000\n",
            "748 episode\tavg score 3.25000\tmax score 3.00000\n",
            "749 episode\tavg score 3.16000\tmax score 1.00000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WFoSwgxYg3fJ",
        "outputId": "cca3588f-6908-4915-ecf5-5e37e85c0224"
      },
      "source": [
        "window=100\n",
        "N = len(scores_mean_hist)\n",
        "running_avg = np.empty(N)\n",
        "for t in range(N):\n",
        "  running_avg[t] = np.mean(scores_mean_hist[max(0, t-window):(t+1)])\n",
        "x = [i for i in range(N)]\n",
        "\n",
        "plt.plot(x, running_avg,label=\"Average Reward\")\n",
        "plt.plot()\n",
        "plt.ylabel('Reward of Model')       \n",
        "plt.xlabel('No. of Episodes')    \n",
        "plt.title(\"Average rewards of all the CI agents\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}